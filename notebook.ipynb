{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0510070d",
   "metadata": {},
   "source": [
    "# Toxicity Classification Homework 2\n",
    "\n",
    "This notebook demonstrates the basic requirements of the civility in communication assignment. We evaluate a rule-based classifier using PerspectiveAPI scores and train a simple logistic regression classifier using TFâ€‘IDF features. We compute performance metrics and false positive rates (FPR) across demographic groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f27718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from toxicity_model import read_data, train_classifier, evaluate_model, compute_fpr, rule_based_perspective, predict_and_save\n",
    "\n",
    "data_dir = 'civility_data'\n",
    "train_df = read_data(f\"{data_dir}/train.tsv\")\n",
    "dev_df = read_data(f\"{data_dir}/dev.tsv\")\n",
    "demo_df = read_data(f\"{data_dir}/mini_demographic_dev.tsv\")\n",
    "test_df = read_data(f\"{data_dir}/test.tsv\")\n",
    "\n",
    "train_df.head(), dev_df.head(), demo_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e776835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rule-based classifier using PerspectiveAPI scores > 0.8\n",
    "rule_preds = rule_based_perspective(dev_df)\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "acc = accuracy_score(dev_df['label'], rule_preds)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(dev_df['label'], rule_preds, labels=['NOT','OFF'], average=None)\n",
    "\n",
    "print('Rule-based classifier results:')\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "print(f'Precision NOT: {prec[0]:.3f}, Recall NOT: {rec[0]:.3f}, F1 NOT: {f1[0]:.3f}')\n",
    "print(f'Precision OFF: {prec[1]:.3f}, Recall OFF: {rec[1]:.3f}, F1 OFF: {f1[1]:.3f}')\n",
    "\n",
    "# FPR for PerspectiveAPI on demographic dev set\n",
    "rule_demo_preds = rule_based_perspective(demo_df)\n",
    "rule_fpr = compute_fpr(rule_demo_preds, demo_df['demographic'])\n",
    "print('\n",
    "Rule-based False Positive Rate per demographic group:')\n",
    "for grp, rate in rule_fpr.items():\n",
    "    print(f'{grp}: {rate:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train logistic regression classifier\n",
    "clf = train_classifier(train_df)\n",
    "results = evaluate_model(clf, dev_df)\n",
    "print('Logistic Regression evaluation:')\n",
    "for k,v in results.items():\n",
    "    print(f'{k}: {v:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_preds_demo = clf.predict(demo_df['text'])\n",
    "log_fpr = compute_fpr(log_preds_demo, demo_df['demographic'])\n",
    "print('Logistic Regression False Positive Rate per demographic group:')\n",
    "for grp, rate in log_fpr.items():\n",
    "    print(f'{grp}: {rate:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on test and save\n",
    "output_file = 'FirstName_LastName_test.tsv'\n",
    "predict_and_save(clf, test_df, output_file)\n",
    "print(f'Test predictions saved to {output_file}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
